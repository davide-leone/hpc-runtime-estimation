{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d54525d-a08a-45e4-8feb-02ef4600a020",
   "metadata": {},
   "source": [
    "## Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3934b2-7b12-43ee-a949-fc047850d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 155764\n",
      "Test  size: 66756\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"datasets/pm100/job_data_train.parquet\")\n",
    "test_df  = pd.read_parquet(\"datasets/pm100/job_data_test.parquet\")\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test  size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0751a52-88e7-4bec-b562-8e57bfc80ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata columns included in retrieval context + prompt\n",
    "META_COLS = [\n",
    "    'User ID',\n",
    "    'Requested Number of Nodes',\n",
    "    'Requested Number of CPU',\n",
    "    'Requested Number of GPU',\n",
    "    'Total Requested Memory',\n",
    "    'Requested Time',\n",
    "    'Submit Time'\n",
    "]\n",
    "\n",
    "TARGET_COL = \"Run Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250eb5b2-bc3b-4b13-a989-0e7e17814069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_ora_text(row):\n",
    "    \"\"\"Convert a row into ORA metadata/prediction formatted text.\"\"\"\n",
    "    meta = \"\"\n",
    "    for key in META_COLS:\n",
    "        meta += f\"metadata:{key}:{row[key]}\\n\"\n",
    "    meta = meta.strip()\n",
    "\n",
    "    # If prediction exists (train), include it\n",
    "    if TARGET_COL in row and not pd.isna(row[TARGET_COL]):\n",
    "        return meta + f\"\\nprediction:{row[TARGET_COL]}\"\n",
    "    else:\n",
    "        return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e509d901-6e3c-4f06-82a7-c40d0c271681",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df.apply(row_to_ora_text, axis=1).tolist()\n",
    "test_texts  = test_df.apply(row_to_ora_text,  axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69395589-e371-4ece-bdff-ca3fd916f6de",
   "metadata": {},
   "source": [
    "## Build or Load the Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c795ae-e873-42bb-841a-e5b6749fadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d868f6-1226-4ba0-9d7a-3afbf62aadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0f32d3-a850-487e-930f-62d00b144ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found existing vectorstore — loading from disk.\n"
     ]
    }
   ],
   "source": [
    "vectorstore_path = \"vectorstore_pm100\"\n",
    "\n",
    "def vectorstore_exists(path):\n",
    "    return os.path.exists(os.path.join(path, \"chroma.sqlite3\"))\n",
    "\n",
    "if vectorstore_exists(vectorstore_path):\n",
    "    print(\"✓ Found existing vectorstore — loading from disk.\")\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=embedding,\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"⏳ No vectorstore found — building from documents (slow).\")\n",
    "\n",
    "    train_documents = [\n",
    "        Document(\n",
    "            page_content=train_texts[i],\n",
    "            metadata={\"userid\": int(train_df.iloc[i][\"User ID\"])}\n",
    "        )\n",
    "        for i in range(len(train_df))\n",
    "    ]\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=train_documents,\n",
    "        embedding=embedding,\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "\n",
    "    print(\"✓ Vectorstore built and automatically persisted to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23faef8c-41dc-4594-8d69-1d501a74f53b",
   "metadata": {},
   "source": [
    "## RAG Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946c67fe-24ee-474a-8df1-12307aaac290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "ORA_PROMPT =  \"\"\"\n",
    "You are an expert in job runtime duration prediction. \n",
    "There are some retrieved history jobs that similar to the job waitting to predict.\n",
    "They are displaied through a diff format. \n",
    "{context}\n",
    "\n",
    "Please predict the job runtime duration based on its matedata, script, and retrieved jobs.\n",
    "The matedata and script of the job waitting to predict is:\n",
    "{question}\n",
    "\n",
    "Your output should only include the runtime, e.g. 10 s. \n",
    "It means that the script is likely to run for 10 seconds. \n",
    "Note: DO NOT OUTPUT ANYTHING OTHER THAN THE RUNTIME.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(ORA_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9054b95-0b62-462c-b701-be3c0dc12e2d",
   "metadata": {},
   "source": [
    "## Load local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e544f4f1-c970-4f7a-8e44-e5636c6ed981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5:7b-instruct\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff85e33-7f27-4280-a4ca-937d406cf888",
   "metadata": {},
   "source": [
    "## Numeric extraction from model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c9f8783-c9ad-4965-a7f2-792366955d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(s):\n",
    "    nums = re.findall(r\"[0-9]+\\.?[0-9]*\", s)\n",
    "    if len(nums) == 0:\n",
    "        return None\n",
    "    return float(nums[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c468e5-6201-40f7-91ae-a47722b804b4",
   "metadata": {},
   "source": [
    "## Prepare test list structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be08dc5-2831-4cd1-aac9-1746c59088b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    r = test_df.iloc[i]\n",
    "    test_list.append({\n",
    "        \"userid\": int(r[\"User ID\"]),\n",
    "        \"time_submit\": float(r[\"Submit Time\"]),\n",
    "        \"data\": test_texts[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c57d1-5a18-4101-92ad-14e7246f0dc2",
   "metadata": {},
   "source": [
    "## Run Inference Over the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f88c28-966f-4abe-ace1-45573661de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"predictions/pm100\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_path, \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44506567-3711-43ed-b54e-8f603c80a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(test_list)\n",
    "B = 10  # number of batches\n",
    "batch_size = N // B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b77b20c-a189-45de-bff0-4785d22622e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found — starting fresh.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(output_file):\n",
    "    print(\"✓ Found previous results, loading...\")\n",
    "    existing_results = pd.read_csv(output_file)\n",
    "    processed_count = len(existing_results)\n",
    "    print(f\"✓ Resuming — {processed_count} samples already completed.\")\n",
    "else:\n",
    "    print(\"No previous results found — starting fresh.\")\n",
    "    existing_results = pd.DataFrame()\n",
    "    processed_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a2afb4-4cb0-4944-a04a-5b7f59c3f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing batch 1/10 (0:6675) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:58:30<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 1/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 2/10 (6675:13350) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:56:48<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 2/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 3/10 (13350:20025) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:59:22<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 3/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 4/10 (20025:26700) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:55:35<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 4/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 5/10 (26700:33375) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:46:02<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 5/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 6/10 (33375:40050) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:47:25<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 6/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 7/10 (40050:46725) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:50:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 7/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 8/10 (46725:53400) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:55:04<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 8/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 9/10 (53400:60075) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6675/6675 [1:59:28<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 9/10 to results/pm100\\predictions.csv\n",
      "\n",
      "--- Processing batch 10/10 (60075:66756) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6681/6681 [2:12:32<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch 10/10 to results/pm100\\predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "K = 5  # same as your original top_k_generic / top_k_user\n",
    "\n",
    "for batch_id in range(B):\n",
    "    start = batch_id * batch_size\n",
    "    end   = (batch_id + 1) * batch_size if batch_id < B-1 else N\n",
    "\n",
    "    # Skip batches already completed\n",
    "    if processed_count >= end:\n",
    "        print(f\"Batch {batch_id+1}/{B} already completed — skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Processing batch {batch_id+1}/{B} ({start}:{end}) ---\")\n",
    "\n",
    "    batch_preds = []\n",
    "    batch_gts   = []\n",
    "    batch_rows  = []\n",
    "\n",
    "    for i in tqdm(range(start, end)):\n",
    "        if i < processed_count:\n",
    "            continue  # already done from previous run\n",
    "\n",
    "        item = test_list[i]\n",
    "        question = item[\"data\"]\n",
    "        userid   = item[\"userid\"]\n",
    "        gt       = float(test_df.iloc[i][TARGET_COL])\n",
    "\n",
    "        # -------- RETRIEVAL --------\n",
    "        retrieved_docs = vectorstore.similarity_search(\n",
    "            question, k=K, filter={\"userid\": userid}\n",
    "        )\n",
    "\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "        # -------- LLM --------\n",
    "        msg = prompt.invoke({\"context\": context, \"question\": question})\n",
    "        response = llm.invoke(msg.messages)\n",
    "        pred = extract_number(response.content)\n",
    "\n",
    "        # fallback\n",
    "        if pred is None or np.isnan(pred):\n",
    "            pred = np.mean([\n",
    "                float(d.page_content.split(\"prediction:\")[1])\n",
    "                for d in retrieved_docs if \"prediction:\" in d.page_content\n",
    "            ])\n",
    "\n",
    "        # store\n",
    "        batch_preds.append(pred)\n",
    "        batch_gts.append(gt)\n",
    "        batch_rows.append({\n",
    "            \"userid\":       userid,\n",
    "            \"time_submit\":  item[\"time_submit\"],\n",
    "            \"gt_runtime\":   gt,\n",
    "            \"pred_runtime_ora\": float(pred)\n",
    "        })\n",
    "\n",
    "        # -------- ONLINE UPDATE --------\n",
    "        new_doc = Document(\n",
    "            page_content=question + f\"\\nprediction:{gt}\",\n",
    "            metadata={\"userid\": userid}\n",
    "        )\n",
    "        vectorstore.add_documents([new_doc])\n",
    "\n",
    "    # -------- Save batch results --------\n",
    "    df_batch = pd.DataFrame(batch_rows)\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        df_batch.to_csv(output_file, mode=\"a\", index=False, header=False)\n",
    "    else:\n",
    "        df_batch.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"✓ Saved batch {batch_id+1}/{B} to {output_file}\")\n",
    "\n",
    "    # update progress\n",
    "    processed_count += len(batch_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023acf0b-f63f-4c25-be70-86b36f34c199",
   "metadata": {},
   "source": [
    "## Save Predictions With User ID + Submit Time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4311a34d-8a24-4e13-9146-d9e8c5d798e7",
   "metadata": {},
   "source": [
    "results = pd.DataFrame({\n",
    "    \"userid\":        [item[\"userid\"] for item in test_list],\n",
    "    \"time_submit\":   [item[\"time_submit\"] for item in test_list],\n",
    "    \"gt_runtime\":    gts,\n",
    "    \"pred_runtime_ora\":  preds,\n",
    "})\n",
    "\n",
    "results.to_csv(\"predictions/pm100/predictions.csv\", index=False)\n",
    "print(\"Saved predictions to predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f270757-344f-4a91-b582-31829a993e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in the file with all other predictions\n",
    "\n",
    "df = pd.read_csv(\"predictions/pm100/predictions.csv\")\n",
    "\n",
    "df[\"pred_runtime_llm\"] = y_pred\n",
    "\n",
    "df.to_csv(\"predictions/pm100/predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d4264-3447-4400-a13f-31bf384ceff5",
   "metadata": {},
   "source": [
    "## Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "864c03b0-a169-44e9-b699-00c4e6e65d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loading full saved results...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✓ Loading full saved results...\")\n",
    "res = pd.read_csv(output_file)\n",
    "\n",
    "gts = res[\"gt_runtime\"].values\n",
    "preds = res[\"pred_runtime_ora\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b809e-b11b-401d-b4e9-bdf454d68ddf",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49cd0ddd-ce5c-4370-9453-85f486437fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae38a4a7-5b81-411e-a817-94289d69629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df[TARGET_COL].values.reshape(-1, 1))\n",
    "\n",
    "gt_scaled   = scaler.transform(np.array(gts).reshape(-1,1)).reshape(-1)\n",
    "pred_scaled = scaler.transform(np.array(preds).reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d97fc3b1-9e35-434e-8053-9a9e062c0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw MAE: 215.2998082569357\n",
      "Raw MSE: 7173488.371082749\n",
      "Raw R2: 0.9586862104268463\n"
     ]
    }
   ],
   "source": [
    "mae_raw = mean_absolute_error(gts, preds)\n",
    "mse_raw = mean_squared_error(gts, preds)\n",
    "r2_raw  = r2_score(gts, preds)\n",
    "\n",
    "print(\"Raw MAE:\", mae_raw)\n",
    "print(\"Raw MSE:\", mse_raw)\n",
    "print(\"Raw R2:\",  r2_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8997479e-f648-410b-968d-71def8b1e3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.002492472890216899\n",
      "MSE: 0.0009613997374420564\n",
      "R2: 0.9586862104268462\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(gt_scaled, pred_scaled)\n",
    "mse = mean_squared_error(gt_scaled, pred_scaled)\n",
    "r2  = r2_score(gt_scaled, pred_scaled)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\",  r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f0d865-4866-4416-b0fc-f0c79b995444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hms(time_value, unit=\"seconds\"):\n",
    "    if unit == \"minutes\":\n",
    "        time_value *= 60  # Convert minutes to seconds\n",
    "    hours, remainder = divmod(time_value, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd5a73c-de70-4aa5-99a9-252bd493a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error (hh:mm:ss)  :  00:03:35\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average prediction error (hh:mm:ss)  :  {convert_to_hms(int(mae_raw))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9f70c-3a69-4d12-9644-069b251bf7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
